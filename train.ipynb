{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from model import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "def process_file(path):\n",
    "    df = pd.read_csv(path, delim_whitespace=True, header=None)\n",
    "    loc = path.split('.')[3] + path.split('.')[4]\n",
    "\n",
    "    df.columns = [\n",
    "        'year', 'month', f'temp_anomaly_{loc}', f'total_error_var_{loc}', f'high_freq_error_var_{loc}',\n",
    "        f'low_freq_error_var_{loc}', f'bias_error_var_{loc}', f'diag_var1_{loc}', f'diag_var2_{loc}', f'diag_var3_{loc}'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=[f'diag_var1_{loc}', f'diag_var2_{loc}', f'diag_var3_{loc}', f'total_error_var_{loc}', f'high_freq_error_var_{loc}',\n",
    "        f'low_freq_error_var_{loc}', f'bias_error_var_{loc}'])\n",
    "\n",
    "    return df\n",
    "\n",
    "data_path = \"data/\"\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        loc_df = process_file(file_path)\n",
    "\n",
    "\n",
    "    # print(file, len(loc_df))\n",
    "    if len(all_data) == 0:\n",
    "        all_data = loc_df\n",
    "    else:\n",
    "        all_data = pd.merge(all_data, loc_df, on = [\"year\", \"month\"])\n",
    "\n",
    "# all_data.insert(0, \"time\", [0] * len(all_data))\n",
    "# all_data['time'] = all_data.apply(lambda x: f'{x[\"year\"]}_{x[\"month\"]}', axis=1)\n",
    "# all_data = all_data.drop(columns=['year', 'month'])\n",
    "\n",
    "all_data.to_csv(\"data/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of segments: 137\n",
      "Length of each input vector (months): 60\n",
      "Length of each target vector (months): 12\n",
      "\n",
      "Tensor Lengths:\n",
      "There are 137 input tensors and 137 target tensors\n",
      "Input tensors length: 60\n",
      "Target tensors length: 12\n"
     ]
    }
   ],
   "source": [
    "def create_segments(data, input_years_length, target_years_length):\n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    \n",
    "    input_months = input_years_length * 12\n",
    "    target_months = target_years_length * 12\n",
    "    total_months = input_months + target_months\n",
    "\n",
    "    start_year = data['year'].min()\n",
    "    end_year = data['year'].max()\n",
    "\n",
    "    for year in range(start_year, end_year - input_years_length - target_years_length + 1):\n",
    "        segment_end_year = year + input_years_length + target_years_length\n",
    "        segment_df = data[(data['year'] >= year) & (data['year'] < segment_end_year)]\n",
    "\n",
    "        if not segment_df.empty:\n",
    "            input_segment = segment_df[:input_months]\n",
    "            target_segment = segment_df[input_months:total_months]\n",
    "            input_data.append(input_segment)\n",
    "            target_data.append(target_segment)\n",
    "\n",
    "    return input_data, target_data\n",
    "\n",
    "# Usage example\n",
    "input_years = 5  # Length of input period in years\n",
    "target_years = 1   # Length of target period in years\n",
    "\n",
    "input_segments, target_segments = create_segments(all_data, input_years, target_years)\n",
    "\n",
    "print(\"# of segments:\", len(input_segments))\n",
    "print(\"Length of each input vector (months):\", len(input_segments[0]))\n",
    "print(\"Length of each target vector (months):\", len(target_segments[0]))\n",
    "\n",
    "# Convert to tensors\n",
    "feature_columns = all_data.columns.difference(['year', 'month'])\n",
    "input_tensors = torch.tensor([df[feature_columns].values for df in input_segments], dtype=torch.float32)\n",
    "target_tensors = torch.tensor([df[feature_columns].values for df in target_segments], dtype=torch.float32)\n",
    "\n",
    "# Print tensor lengths\n",
    "print(\"\\nTensor Lengths:\")\n",
    "print(f\"There are {len(input_tensors)} input tensors and {len(target_tensors)} target tensors\")\n",
    "print(f\"Input tensors length: {len(input_tensors[0])}\")\n",
    "print(f\"Target tensors length: {len(target_tensors[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([8, 60, 15])\n",
      "Target batch shape: torch.Size([8, 12, 15])\n"
     ]
    }
   ],
   "source": [
    "from dataset import TimeSeriesDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "batch_size = 8\n",
    "\n",
    "ts_dataset = TimeSeriesDataset(input_tensors, target_tensors)\n",
    "train_size = int(0.8 * len(ts_dataset))  # e.g., 80% of data for training\n",
    "val_size = len(ts_dataset) - train_size  # remaining for validation\n",
    "\n",
    "# Randomly split the dataset into training and validation datasets\n",
    "train_dataset, val_dataset = random_split(ts_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for both training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # Usually, no need to shuffle the validation set\n",
    "\n",
    "input_batch, target_batch = next(iter(train_loader))\n",
    "\n",
    "# Print the shapes\n",
    "print(f'Input batch shape: {input_batch.shape}')  # e.g., torch.Size([8, 120, 15])\n",
    "print(f'Target batch shape: {target_batch.shape}')  # e.g., torch.Size([8, 12, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these parameters\n",
    "\n",
    "d_model = 15\n",
    "ffn_hidden = 2048\n",
    "num_heads = 5\n",
    "drop_prob = 0.1\n",
    "num_layers = 10\n",
    "\n",
    "transformer = Transformer(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12, 15]),\n",
       " tensor([[[ 3.8440e-01,  9.6435e-01,  3.7524e-01,  ..., -1.3515e-01,\n",
       "           -4.6454e-01, -4.0719e-01],\n",
       "          [ 5.8493e-01,  9.3210e-01,  5.3819e-01,  ...,  3.6844e-01,\n",
       "           -1.0467e+00, -1.6403e-01],\n",
       "          [ 2.1902e-01,  4.9124e-01, -1.1541e-01,  ...,  7.5895e-01,\n",
       "            1.4420e-01,  3.9245e-01],\n",
       "          ...,\n",
       "          [ 2.5817e-01,  7.4476e-01, -4.3541e-01,  ...,  7.5843e-01,\n",
       "           -1.0037e+00, -1.7318e-01],\n",
       "          [ 9.9909e-02,  5.9469e-01,  2.4657e-01,  ...,  1.8029e-01,\n",
       "           -1.0473e-01, -2.0503e-01],\n",
       "          [-1.6641e-01,  5.8088e-01,  8.5724e-02,  ..., -2.6673e-01,\n",
       "            2.9546e-01, -8.3550e-01]],\n",
       " \n",
       "         [[ 3.7830e-01,  5.0361e-01,  2.2965e-01,  ...,  3.7804e-01,\n",
       "           -1.1652e+00,  2.2134e-01],\n",
       "          [ 8.2682e-01,  8.1350e-02,  3.2621e-01,  ...,  5.6927e-01,\n",
       "           -1.2298e+00,  1.0841e+00],\n",
       "          [ 8.8740e-02,  1.4449e-01,  3.1841e-02,  ...,  1.3954e+00,\n",
       "           -1.3678e+00,  4.0665e-01],\n",
       "          ...,\n",
       "          [ 6.8076e-03,  4.8395e-01, -1.3317e-01,  ...,  8.2512e-01,\n",
       "           -1.1723e+00, -7.3158e-01],\n",
       "          [ 3.3219e-01,  8.7296e-02, -1.1378e-02,  ...,  1.9645e-01,\n",
       "           -5.0951e-01, -4.2928e-01],\n",
       "          [ 7.5587e-01,  2.9104e-01, -1.2427e-01,  ..., -3.7918e-02,\n",
       "           -3.5254e-01, -3.4597e-01]],\n",
       " \n",
       "         [[ 5.2557e-01,  6.0235e-01,  4.6031e-01,  ..., -5.4929e-01,\n",
       "           -2.1740e-01, -3.1670e-02],\n",
       "          [ 4.0107e-01,  5.4398e-01,  1.9396e-02,  ..., -6.2319e-01,\n",
       "           -8.7747e-02, -2.1292e-01],\n",
       "          [-2.6636e-02,  4.4173e-01, -1.2656e-01,  ...,  1.2613e-01,\n",
       "            6.3661e-02, -2.1258e-01],\n",
       "          ...,\n",
       "          [ 5.1107e-01,  4.9876e-01, -2.3967e-01,  ...,  3.6508e-01,\n",
       "           -8.0015e-01, -7.1076e-01],\n",
       "          [ 4.4078e-01,  8.2902e-02, -3.0771e-01,  ..., -8.0903e-02,\n",
       "           -1.1519e-01, -7.6737e-01],\n",
       "          [ 1.7682e-01,  1.2891e-01, -4.0532e-01,  ..., -1.4555e-01,\n",
       "            1.1385e-01, -5.8315e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1841e-01,  8.0681e-01, -2.2441e-02,  ..., -2.5450e-01,\n",
       "           -3.9992e-01, -3.4844e-01],\n",
       "          [ 3.7858e-01,  3.4268e-01, -1.0967e-01,  ..., -4.5113e-01,\n",
       "            8.0460e-03, -2.4526e-01],\n",
       "          [ 4.1814e-01, -2.0342e-01, -1.4651e-01,  ..., -2.6845e-01,\n",
       "            3.6954e-01,  6.7191e-01],\n",
       "          ...,\n",
       "          [ 3.1673e-01,  3.9163e-01, -6.9428e-01,  ...,  6.2526e-01,\n",
       "           -8.5585e-01, -4.9384e-01],\n",
       "          [ 3.8405e-01,  3.3024e-01, -4.2365e-01,  ..., -2.9613e-01,\n",
       "            1.2542e-01, -6.1992e-01],\n",
       "          [ 2.9974e-01,  3.5414e-01, -2.3806e-01,  ..., -5.1588e-01,\n",
       "            2.3163e-01, -1.0176e+00]],\n",
       " \n",
       "         [[ 4.7497e-01,  5.9024e-01,  3.7958e-01,  ..., -3.3862e-01,\n",
       "           -5.1579e-01,  2.3131e-01],\n",
       "          [ 4.5978e-01,  6.3885e-01,  1.9383e-01,  ..., -1.7686e-01,\n",
       "           -5.2158e-01,  3.2731e-02],\n",
       "          [ 2.4768e-01,  1.5409e-01,  1.4137e-01,  ...,  3.2349e-02,\n",
       "           -5.0680e-02,  3.8148e-01],\n",
       "          ...,\n",
       "          [ 4.2469e-01,  5.8291e-01, -4.6518e-01,  ...,  6.0159e-01,\n",
       "           -1.0061e+00, -6.9252e-02],\n",
       "          [ 2.4083e-01,  2.0801e-01,  3.2715e-01,  ...,  7.0951e-01,\n",
       "           -8.4053e-01,  2.7478e-01],\n",
       "          [ 3.3870e-02,  2.5322e-02, -9.9384e-03,  ...,  1.0891e+00,\n",
       "           -4.0392e-01,  3.8904e-01]],\n",
       " \n",
       "         [[-1.4067e-01,  5.6356e-01, -1.3387e-01,  ..., -2.0858e-01,\n",
       "           -3.2064e-01, -2.6810e-01],\n",
       "          [ 1.7451e-01,  6.4211e-01,  3.1136e-01,  ..., -4.7948e-01,\n",
       "            1.6078e-02, -5.8863e-01],\n",
       "          [ 4.4409e-01,  1.6936e-01,  3.1953e-02,  ...,  1.5401e-02,\n",
       "            6.7156e-02,  5.1660e-01],\n",
       "          ...,\n",
       "          [ 1.1470e-03,  8.0037e-01, -4.0508e-01,  ...,  9.8970e-01,\n",
       "           -6.7723e-01,  2.7843e-01],\n",
       "          [ 2.7353e-01,  7.0928e-01, -8.3085e-02,  ...,  1.0454e-01,\n",
       "           -2.7224e-01, -7.3647e-01],\n",
       "          [ 1.7855e-01,  4.5254e-01,  9.5077e-04,  ...,  9.1415e-02,\n",
       "           -5.6960e-01,  2.0976e-02]]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = transformer(input_batch, target_batch)\n",
    "test_output.size(), test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(params=transformer.parameters(), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3230\n",
      "Epoch 2/100, Loss: 0.2784\n",
      "Epoch 3/100, Loss: 0.2487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits_batch, target_batch)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/3.10/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    transformer.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        logits_batch = transformer(input_batch, target_batch)\n",
    "\n",
    "        loss = criterion(logits_batch, target_batch)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Calculate average loss for the epoch\n",
    "    train_loss /= (len(input_tensors) // batch_size)\n",
    "\n",
    "    # transformer.eval()\n",
    "    # with torch.inference_mode():\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Print epoch stats\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}')\n",
    "\n",
    "    torch.save(transformer.state_dict(), f'saved_models/transformer_epoch_{epoch+1}_batch_{batch+1}.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
