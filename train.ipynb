{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from model import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "def process_file(path):\n",
    "    df = pd.read_csv(path, delim_whitespace=True, header=None)\n",
    "    loc = path.split('.')[3] + path.split('.')[4]\n",
    "\n",
    "    df.columns = [\n",
    "        'year', 'month', f'temp_anomaly_{loc}', f'total_error_var_{loc}', f'high_freq_error_var_{loc}',\n",
    "        f'low_freq_error_var_{loc}', f'bias_error_var_{loc}', f'diag_var1_{loc}', f'diag_var2_{loc}', f'diag_var3_{loc}'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=[f'diag_var1_{loc}', f'diag_var2_{loc}', f'diag_var3_{loc}', f'total_error_var_{loc}', f'high_freq_error_var_{loc}',\n",
    "        f'low_freq_error_var_{loc}', f'bias_error_var_{loc}'])\n",
    "\n",
    "    return df\n",
    "\n",
    "data_path = \"data/\"\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        loc_df = process_file(file_path)\n",
    "\n",
    "\n",
    "    # print(file, len(loc_df))\n",
    "    if len(all_data) == 0:\n",
    "        all_data = loc_df\n",
    "    else:\n",
    "        all_data = pd.merge(all_data, loc_df, on = [\"year\", \"month\"])\n",
    "\n",
    "# all_data.insert(0, \"time\", [0] * len(all_data))\n",
    "# all_data['time'] = all_data.apply(lambda x: f'{x[\"year\"]}_{x[\"month\"]}', axis=1)\n",
    "# all_data = all_data.drop(columns=['year', 'month'])\n",
    "\n",
    "all_data.to_csv(\"data/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each segment: (132, 17)\n",
      "# of segments: 13\n",
      "\n",
      "Length of each input vector (120 months / 10 years): 120\n",
      "Length of each target vector (12 months / 1 year): 12\n",
      "\n",
      "Use 120 months to predict 12 months\n",
      "\n",
      "Tensor Lengths:\n",
      "There are 13 input tensors and 13 target tensors corresponding to each of the 13 intervals\n",
      "Input tensors legnth: 120\n",
      "Target tensors legnth: 12\n"
     ]
    }
   ],
   "source": [
    "# Segmentation\n",
    "\n",
    "segments = []\n",
    "start_year = all_data['year'].min()\n",
    "end_year = all_data['year'].max()\n",
    "\n",
    "for year in range(start_year, end_year, 11):\n",
    "    # print(\"start year: \", year)\n",
    "    # Get the subset of data for the current 11-year segment\n",
    "    segment_end = min(year + 11, end_year + 1)  # Ensure we don't go beyond the last year\n",
    "    # print(\"end_year: \", segment_end)\n",
    "    segment_df = all_data[(all_data['year'] >= year) & (all_data['year'] < segment_end)]\n",
    "    \n",
    "    if not segment_df.empty:\n",
    "        segments.append(segment_df)\n",
    "\n",
    "# Each element (13 elements) in segment is a segment of 11 years or 132 months - which is the dimension of each segment\n",
    "print(\"Length of each segment:\", segments[0].shape)\n",
    "print(\"# of segments:\", len(segments))\n",
    "\n",
    "input_data = []\n",
    "target_data = []\n",
    "\n",
    "feature_columns = all_data.columns.difference(['year', 'month'])\n",
    "\n",
    "for segment in segments:\n",
    "    # Extract 10 years of data as input\n",
    "    input_years = segment[:120]\n",
    "    input_data.append(input_years)\n",
    "\n",
    "    # Extract the 11th year's data as target\n",
    "    target_year = segment[120:132]\n",
    "    target_data.append(target_year)\n",
    "    \n",
    "# In input_data, there are 13 elements, corresponding to the 13 segments of 10 years which is the input. \n",
    "\n",
    "print(\"\\nLength of each input vector (120 months / 10 years):\", len(input_data[0]))\n",
    "print(\"Length of each target vector (12 months / 1 year):\", len(target_data[0]))\n",
    "\n",
    "print(f\"\\nUse {len(input_data[0])} months to predict {len(target_data[0])} months\")\n",
    "\n",
    "# Grab only the values of each dataframe and put them into a 2d array. Each element of the array represents one input vector.\n",
    "input_data_value = [df[feature_columns].values for df in input_data]\n",
    "target_data_value = [df[feature_columns].values for df in target_data]\n",
    "\n",
    "# Make them Pytorch tensors\n",
    "input_tensors = torch.tensor(input_data_value, dtype=torch.float32)\n",
    "target_tensors = torch.tensor(target_data_value, dtype=torch.float32)\n",
    "\n",
    "# Tensor lengths\n",
    "print(\"\\nTensor Lengths:\")\n",
    "\n",
    "print(f\"There are {len(input_tensors)} input tensors and {len(target_tensors)} target tensors corresponding to each of the 13 intervals\")\n",
    "print(f\"Input tensors legnth: {len(input_tensors[0])}\")\n",
    "print(f\"Target tensors legnth: {len(target_tensors[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 120, 15])\n",
      "torch.Size([8, 12, 15])\n"
     ]
    }
   ],
   "source": [
    "# Batch Size and Random Shuffling of the data\n",
    "\n",
    "def get_random_batch(input_tensors, target_tensors, batch_size):\n",
    "    # Ensure batch size is not larger than the dataset\n",
    "    batch_size = min(batch_size, len(input_tensors))\n",
    "\n",
    "    # Randomly select indices for the batch\n",
    "    indices = np.random.choice(len(input_tensors), batch_size, replace=False)\n",
    "\n",
    "    # Extract batches using the selected indices\n",
    "    input_batch = input_tensors[indices]\n",
    "    target_batch = target_tensors[indices]\n",
    "\n",
    "    return input_batch, target_batch\n",
    "\n",
    "batch_size = 8  # Set your batch size\n",
    "input_batch, target_batch = get_random_batch(input_tensors, target_tensors, batch_size)\n",
    "\n",
    "print(input_batch.shape) # 8 batches x 120 months (10 years) x 15 locations\n",
    "print(target_batch.shape) # 8 batches x 12 months (1 year) x 15 locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these parameters\n",
    "\n",
    "d_model = 15\n",
    "batch_size = 8\n",
    "ffn_hidden = 2048\n",
    "num_heads = 5\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "\n",
    "transformer = Transformer(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12, 15]),\n",
       " tensor([[[ 1.5888e-01, -5.1789e-01,  3.8739e-01,  ...,  1.0995e+00,\n",
       "            1.7238e-01,  3.2223e-01],\n",
       "          [ 5.8304e-01, -8.2627e-01, -1.3868e-02,  ...,  7.6242e-01,\n",
       "            1.2629e+00,  7.7521e-01],\n",
       "          [ 5.5063e-01, -5.6164e-01, -3.6300e-01,  ...,  4.3689e-03,\n",
       "            9.9995e-01,  9.2244e-01],\n",
       "          ...,\n",
       "          [ 2.3619e-01, -5.8041e-01, -7.0785e-01,  ...,  6.4826e-02,\n",
       "            2.6943e-01,  2.5088e-01],\n",
       "          [ 1.6135e-01, -3.9725e-01, -5.7036e-01,  ..., -8.7249e-03,\n",
       "           -1.1513e+00, -9.2528e-01],\n",
       "          [-1.5883e-01, -7.9643e-01, -3.4784e-01,  ..., -2.4040e-01,\n",
       "            1.1470e-01, -1.7130e-01]],\n",
       " \n",
       "         [[-3.5559e-01, -4.0591e-01, -5.7647e-01,  ...,  2.4523e-01,\n",
       "            6.5355e-02, -1.8971e-01],\n",
       "          [-3.9606e-01,  3.8251e-01, -5.1888e-01,  ...,  6.5567e-02,\n",
       "           -1.1031e+00, -9.7499e-01],\n",
       "          [-1.8251e-01,  2.7164e-01, -4.2413e-01,  ...,  1.5890e-01,\n",
       "           -1.1823e+00, -1.0910e+00],\n",
       "          ...,\n",
       "          [-7.1939e-02, -5.1172e-01,  2.4463e-01,  ...,  6.3028e-01,\n",
       "           -2.3134e-01,  5.2190e-02],\n",
       "          [ 1.1234e+00, -8.3310e-01, -4.5469e-04,  ...,  2.3614e-01,\n",
       "           -4.0198e-01, -3.1278e-01],\n",
       "          [ 8.9245e-01, -1.4127e+00, -1.1300e-01,  ...,  6.6439e-01,\n",
       "            5.7472e-01,  5.6716e-01]],\n",
       " \n",
       "         [[-2.9383e-02,  8.6573e-02, -5.4855e-01,  ...,  7.3517e-01,\n",
       "            7.1787e-01,  7.8021e-01],\n",
       "          [ 3.2789e-01, -2.4183e-01, -1.7749e-01,  ...,  9.0938e-01,\n",
       "            1.2056e+00,  1.6134e+00],\n",
       "          [ 3.0634e-01, -4.4526e-01, -1.6936e-01,  ...,  7.6209e-02,\n",
       "            1.2288e+00,  1.0233e+00],\n",
       "          ...,\n",
       "          [-2.5813e-01,  2.3961e-01, -1.2992e-01,  ..., -1.0932e-01,\n",
       "           -1.1491e+00, -1.1928e+00],\n",
       "          [-2.2439e-01,  1.9524e-01, -3.6821e-01,  ..., -7.2771e-01,\n",
       "           -1.3668e+00, -1.3198e+00],\n",
       "          [-8.7321e-01, -2.5814e-01, -2.4312e-01,  ..., -4.0223e-01,\n",
       "           -9.9563e-01, -1.2108e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.0035e-01,  5.9868e-01, -7.2783e-01,  ...,  3.8835e-01,\n",
       "            3.4300e-01,  6.7335e-01],\n",
       "          [-2.4757e-01,  5.5998e-01, -4.6528e-01,  ...,  2.6905e-01,\n",
       "           -8.8611e-01, -5.8096e-01],\n",
       "          [ 4.4316e-01, -3.8422e-01, -4.9376e-01,  ..., -5.4912e-03,\n",
       "            9.0344e-01,  8.1372e-01],\n",
       "          ...,\n",
       "          [-1.4468e-01, -3.6898e-02, -5.7011e-01,  ...,  8.7998e-02,\n",
       "           -9.8736e-01, -6.6634e-01],\n",
       "          [-2.5064e-01, -2.0542e-01, -2.5578e-01,  ..., -7.4372e-02,\n",
       "           -1.5162e+00, -1.2529e+00],\n",
       "          [-3.5276e-01, -2.2186e-01, -3.4654e-01,  ...,  3.7751e-02,\n",
       "           -1.3310e+00, -1.1925e+00]],\n",
       " \n",
       "         [[ 6.3391e-01, -4.1368e-01, -4.9283e-01,  ...,  4.3259e-01,\n",
       "            1.1145e+00,  1.2007e+00],\n",
       "          [ 9.9966e-01, -5.3987e-01, -4.6569e-01,  ...,  5.2469e-01,\n",
       "            1.2718e+00,  1.4393e+00],\n",
       "          [ 4.5251e-01, -7.0726e-01, -1.1764e-01,  ...,  8.7376e-02,\n",
       "            1.2580e+00,  1.3009e+00],\n",
       "          ...,\n",
       "          [-3.0409e-01,  2.1540e-01, -6.2902e-01,  ...,  5.7387e-03,\n",
       "           -8.4509e-01, -6.4740e-01],\n",
       "          [ 1.4196e-01, -6.8539e-01, -7.8193e-01,  ..., -4.3883e-01,\n",
       "           -3.9947e-02, -2.2797e-01],\n",
       "          [ 2.0987e-01, -8.5541e-01, -4.0773e-01,  ..., -5.4247e-01,\n",
       "           -1.6788e-02, -6.3281e-02]],\n",
       " \n",
       "         [[-5.1700e-01,  1.3404e-01, -6.0373e-01,  ...,  8.0318e-02,\n",
       "           -1.3775e+00, -1.0737e+00],\n",
       "          [-2.0723e-01, -1.4319e-01, -1.1766e-01,  ..., -6.7470e-02,\n",
       "           -1.2839e+00, -1.3261e+00],\n",
       "          [-5.2381e-02,  1.3631e-01, -2.8572e-01,  ..., -6.7084e-02,\n",
       "           -1.3826e+00, -1.3439e+00],\n",
       "          ...,\n",
       "          [ 1.2882e-01, -1.9500e-01,  7.0413e-02,  ...,  2.6782e-01,\n",
       "           -1.2161e+00, -9.8924e-01],\n",
       "          [ 2.0355e-01, -3.9045e-01, -1.5231e-01,  ...,  5.3533e-01,\n",
       "           -8.4762e-01, -6.2028e-01],\n",
       "          [ 1.7537e-01, -5.6683e-01,  3.2659e-01,  ...,  4.5667e-01,\n",
       "           -7.2190e-01, -4.0817e-01]]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = transformer(input_batch, target_batch)\n",
    "test_output.size(), test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(params=transformer.parameters(), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    transformer.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in range(len(input_tensors) // batch_size):\n",
    "        input_batch, target_batch = get_random_batch(input_tensors, target_tensors, batch_size)\n",
    "\n",
    "        logits_batch = transformer(input_batch, target_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(logits_batch, target_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss /= (len(input_tensors) // batch_size)\n",
    "    \n",
    "    # Print epoch stats\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    torch.save(transformer.state_dict(), f'saved_models/transformer_epoch_{epoch+1}_batch_{batch+1}.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
